\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fullpage}
\usepackage{makecell}
\usepackage{tabularx}
\usepackage{mathdots}

\usepackage[dvipsnames]{xcolor}
\usepackage{tikz,tkz-euclide}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{quotes,angles,calc,intersections}
\usepackage{pgfplots}

\usepackage{titling}
\usepackage{pdfpages}
\usepackage{color}
\usepackage{hyperref}

\usepackage{common}
\usepackage{linear}

\begin{document}

\title{Mathematics of Images and Shapes Notes}
\author{Brendan Burkhart}
\maketitle

\tableofcontents
\newpage

\section{Mathematically Describing Images}

Traditionally, images have been modeled as graphs (or level sets) of continuous functions defined on a rectangular domain $D \subset \R^2$, and codomain $P \subset \R$. \[D = \left[0, R_1\right] \times \left[0, R_2\right] \subset \R^2\] \[P = \left[0, L\right] \subset \R\] \[f : D \to P\]

This definition is for grayscale (black and white), images, not color images. A value of $0$ would correspond to the color black, and $L$ to white, and everything in between would be various shades of gray.

To perform computational work with images, it is useful to discretize images. This can be done by sampling the functions at $(m, n)$ for all $m \in \{0, \ldots, M-1\}$ and $n \in \{0, \ldots, N-1\}$ where $M$ and $N$ are the number of pixels on the $y$-axis and $x$-axis respectively. $L$ is chosen to be $2^b-1$ where $b$ is the number of bits per pixel. We can then discretize the domain into $\mathbb{P} = \{0, \ldots, 2^b-1\}$. Discretized images are the graph of a discrete function $I: \mathbb{D} \to \mathbb{P}$, where $\mathbb{D} = \{0, \ldots, M-1\} \times \{0, \ldots, N-1\}$. This can be represented as an $M \times N$ matrix $I(i, j)$ where $(i, j) \in \mathbb{D}$.

Color images can be represented as three of these matrices (or a single three-dimensional matrix), each corresponding to one dimension of a color space, such as RGB or HSV.

\section{Point Operations}

\begin{defn}
    Given a mapping $T: \mathbb{P} \to \mathbb{P}$, a \emph{point operation} on an image $I: \mathbb{D} \to \mathbb{P}$ is defined as $J(i, j) = T(I(i, j))$ for all $(i, j) \in \mathbb{D}$.
\end{defn}

\begin{rmk}
    $J(i, j)$ depends only on $I(i, j)$, not on any other pixel.
\end{rmk}

\begin{defn}
    The \emph{Heaviside function} is $H: \R \to \R$, where $H(x) = \left\{
    \begin{array}{lr}
        1 & : x \geq 0 \\
        0 & : x < 0
    \end{array}\right.$
\end{defn}

\begin{figure}[ht!]
    \centering
    \begin{tikzpicture}[scale=1.0]
        \begin{axis}[
            axis x line=middle,
            axis y line=middle,
            ymin=0,ymax=256,ylabel=$y$,
            xmin=0,xmax=256,xlabel=$x$
        ]
            \addplot[domain=0:100, blue, ultra thick] {0};
            \addplot[domain=100:256, blue, ultra thick] {255};
            \addplot[color=blue,fill=white,only marks,mark=*] coordinates{(100,0)};
            \addplot[color=blue,only marks,mark=*] coordinates{(100,255)};
        \end{axis}
    \end{tikzpicture}
\caption{Graph of threshold function $(L-1)H(r - t)$ where $L = 256$ and $t = 100$.}
\label{fig:threshold}
\end{figure}

\begin{figure}[ht!]
    \centering
    \begin{tikzpicture}[scale=01.0]
        \begin{axis}[
            axis x line=middle,
            axis y line=middle,
            ymin=0,ymax=256,ylabel=$y$,
            xmin=0,xmax=256,xlabel=$x$
            ]
        \addplot[domain=0:256, blue, ultra thick, samples=200] {255*(x/255)^0.25};
        \addplot[domain=0:256, green, ultra thick, samples=200] {255*(x/255)^4.0};
    \end{axis}
    \end{tikzpicture}
\caption{Graph of gamma function $(L-1)\left(\frac{r}{L-1}\right)^\gamma$ where $\gamma = 4$ (green) and $\gamma = \frac{1}{4}$ (blue).}
\label{fig:gamma}
\end{figure}

\begin{figure}[ht!]
    \centering
    \begin{tikzpicture}[scale=01.0]
        \begin{axis}[
            axis x line=middle,
            axis y line=middle,
            ymin=0,ymax=256,ylabel=$y$,
            xmin=0,xmax=256,xlabel=$x$
            ]
        \addplot[domain=0:256, blue, ultra thick] {127.5 + 127.5*sin(deg(0.5*pi*(x - 127.5)/127.5))};
    \end{axis}
    \end{tikzpicture}
\caption{Graph of contrast enhancement $c + c\sin\left(\frac{\pi(r-c)}{2c}\right)$.}
\label{fig:contrast}
\end{figure}

For the following four examples, let $I = \begin{bmatrix}
    0 & 0 & 0\\ 255 & 255 & 0 \\ 255 & 0 & 100
\end{bmatrix}$, so $\mathbb{D} = \left[0, 2\right] \times \left[0, 2\right]$, and let $L = 2^8 = 256$ so $\mathbb{P} = \left[0, 256 - 1\right]$.

\begin{exmp}
    Identity: $T: r \mapsto r$, $J = \begin{bmatrix}
        0 & 0 & 0\\ 255 & 255 & 0 \\ 255 & 0 & 100
    \end{bmatrix}$.
\end{exmp}

\begin{exmp}
    Negative: $T: r \mapsto (L-1) - r$, $J = \begin{bmatrix}
        255 & 255 & 255 \\ 0 & 0 & 255 \\ 0 & 255 & 155
    \end{bmatrix}$.
\end{exmp}

\begin{exmp}
    Converting a grayscale image to B\&W uses a threshold function, an example of which is shown in Figure \ref{fig:threshold}. \[T: r \mapsto (L-1)H(r - t)\] where $L \geq t \geq 0$. \[J = \begin{bmatrix}
        0 & 0 & 0\\ 255 & 255 & 0 \\ 255 & 0 & 0
    \end{bmatrix}\]
\end{exmp}

\begin{exmp}
    Gamma-correction uses the gamma function, two examples of which are shown in Figure \ref{fig:gamma}. \[T: r \mapsto (L-1)\left(\frac{r}{L-1}\right)^\gamma\] where $\gamma > 0$. When $\gamma > 1$ the image is darkened, when $\gamma < 1$ the image is brightened, and when $\gamma = 1$ the image is unchanged.
\end{exmp}

\begin{exmp}
    Contrast-enhancement can be done using the function shown in Figure \ref{fig:contrast}. \[T: r \mapsto c + c\sin\left(\frac{\pi(r-c)}{2c}\right)\] where $c = \frac{L - 1}{2}$. When $\gamma > 1$ the image is darkened, when $\gamma < 1$ the image is brightened, and when $\gamma = 1$ the image is unchanged.
\end{exmp}

\section{Filtering and Convolutions}

\begin{defn}
    A \emph{filter mask} $w$ is a $(2k_1 + 1) \times (2k_2 + 1)$ matrix, where $k_1, k_2 \in \N$.

    \[w = \begin{bmatrix}
        w{(-k_1, -k_2)} & \cdots & w{(-k_1, 0)} & \cdots & w{(-k_1, k_2)} \\
        \vdots & \ddots & \vdots & \iddots & \vdots \\
        w{(0, -k_2)} & \cdots & w{(0, 0)} & \cdots & w{(0, k_2)} \\
        \vdots & \iddots & \vdots & \ddots & \vdots \\
        w{(k_1, -k_2)} & \cdots & w{(k_1, 0)} & \cdots & w{(k_1, k_2)} \\
    \end{bmatrix}\]
\end{defn}

\begin{exmp}
    A \emph{mean} or \emph{uniform averaging} filter uses a filter mask where
    \[w = \frac{1}{k_1k_2}\begin{bmatrix}
        1 & \cdots & 1 & \cdots & 1 \\
        \vdots & \ddots & \vdots & \iddots & \vdots \\
        1 & \cdots & 1 & \cdots & 1 \\
        \vdots & \iddots & \vdots & \ddots & \vdots \\
        1 & \cdots & 1 & \cdots & 1 \\
    \end{bmatrix}.\] Typically, averaging filters are used with a $3 \times 3$ or $5 \times 5$ mask.
\end{exmp}

\begin{exmp}
    A \emph{Gaussian} filter uses a filter mask created by sampling a Gaussian function \[g(x, y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2+y^2}{2\sigma^2}}\] where
    \[w = \begin{bmatrix}
        g(-k_1, -k_2) & \cdots & g(-k_1, 0) & \cdots & g(-k_1, k_2) \\
        \vdots & \ddots & \vdots & \iddots & \vdots \\
        g(0, -k_2) & \cdots & g(0, 0) & \cdots & g(0, k_2) \\
        \vdots & \iddots & \vdots & \ddots & \vdots \\
        g(k_1, -k_2) & \cdots & g(k_1, 0) & \cdots & g(k_1, k_2) \\
    \end{bmatrix}.\]
\end{exmp}

\begin{defn}
    Let $I: \mathbb{D} \to \mathbb{P}$ be an image, and $w$ a filter mask. Then applying the \emph{filter} represented by $w$ to $I$ results in the image $J: \mathbb{D} \to \mathbb{D}$ defined by: \[J(i, j) = \sum_{u = -k_1}^{k_1}\sum_{v = -k_2}^{k_2}I(i + u, j + v)w(u, v).\]
\end{defn}

Notice that filters cannot be naively applied to the $k_1 + 1$ top/bottom-most rows, nor the $k_2 + 1$ left/right-most columns of $I$, since entries with indices outside the image do not exist. This problem can be solved via a variety of strategies.
\begin{itemize}
    \item One option is to zero-pad the image. For example, if $I$ is $3 \times 3$, then $I(2, 3)$ and $I(-1, 2)$ would both be $0$.
    \item Zero-padding a bright image could cause strange filter behavior near the edges, so the image could instead be padded with the average value of the entire image.
    \item Constant-padding with the average could still cause issues if parts of the image's edges differ significantly from the rest of the image, so nearest-neighbor padding can be used instead. This is where the added padding pixels have the same value as the nearest pixel from the image.
    \[\begin{array}{c c||c c c}
        3 & 3 & 3 & 7 & 2 \\
        3 & 3 & 3 & 7 & 2\\
        \hline \hline
        3 & 3 & 3 & 7 & 2 \\
        5 & 5 & 5 & 1 & 6 \\
        8 & 8 & 8 & 9 & 4 \\
    \end{array}\]
    \item Nearest-neighbor can cause issues with detecting edges that are near/coincide with the edge of the image itself. This can be solved by instead by using reflective (also symmetric)padding. The reflection of the image's outer rows/columns can help accentuate an edge if one exists, rather than suppressing it like nearest-neighbor.
    \[\begin{array}{c c||c c c}
        1 & 5 & 5 & 1 & 6 \\
        7 & 3 & 3 & 7 & 2\\
        \hline \hline
        7 & 3 & 3 & 7 & 2 \\
        1 & 5 & 5 & 1 & 6 \\
        9 & 8 & 8 & 9 & 4 \\
    \end{array}\]
    \item Periodic padding tiles the image, so accessing entries past one side will wrap around and access entries on the other side. Can be useful if images can an inherent periodicity that reflective padding doesn't take advantage of.
\end{itemize}

\begin{defn}
    Let $I: \Z^2 \to \R$ be a function representing an image $I_0: \mathbb{D} \to \mathbb{P}$ take has been extended to infinity by zero-padding. Note that $I_0$ could be another image that has been padded in some way. Let $h: \Z^2 \to \R$ be a function (called the \emph{kernel} or \emph{convolution kernel}). Then we define the \emph{convolution} of $I$ and $h$, denoted by $I * h$, as \[(I * h)(i, j) = \sum_{k=-\infty}^{\infty}\sum_{l=-\infty}I(i - k, j - l)(h, k, l).\] Notice the similarities to the definition of applying a filter, and the differences --- there on no bounds, and the image entries are indexed using $i - k$ and $i - l$ rather than $i + u$ and $i + v$.
\end{defn}

Filtering can be defined in terms of convolution. To apply a $(2k_1 + 1) \times (2k_2 + 1)$ filter mask $w$ to an $n \times m$ image $I$ (which may be padded), define $h(k, l) = w(-k, l)$, and extend both $h$ and $I$ to infinity by zero-padding. Then $J = I * H$.

\begin{exmp}\proofbreak
    \begin{itemize}
        \item The mean filter mask can be used as a convolution kernel to evenly blur images, smoothing them out and removing noise.
        \item The Gaussian blurring can be performed by using the Gaussian mask as a convolution kernel, resulting in less significant smoothing effects while still working to denoise the image.
    \end{itemize}
\end{exmp}

Convolution is a linear operation, however several useful filtering operations are non-linear. One example is median blurring. Similarly to how mean filtering defines $J(i, j)$ to be the mean of the neighborhood of $I(i, j)$, median blurring uses the median of the neighborhood of $I(i, j)$. This can result in superior denoising, while better preserving edges. However, it is more computationally expensive than either mean or Gaussian blurring.

\section{Partial Derivatives for Images}

\begin{defn}
    When $\Delta x$ is small enough, $f'(x_0)$ can be approximated using the \emph{forward difference formula}: \[f'(x_0) \approx \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}.\]
\end{defn}

\begin{defn}
    When $\Delta x$ is small enough, $f'(x_0)$ can be approximated using the \emph{back difference formula}: \[f'(x_0) \approx \frac{f(x_0) - f(x_0 - \Delta x)}{\Delta x}.\]
\end{defn}

\begin{rmk}
    Often, for a particular function at a particular point, the forward difference formula will overestimate the derivative and the backward difference formula will underestimate it, or vice versa. Thus, the average often gives a better approximation.
\end{rmk}

\begin{defn}
    The \emph{central difference formula} (also the \emph{midpoint formula)} approximates $f'(x_0)$ for a function $f$ as the average of the forward and backward difference functions. \[f'(x_0) \approx \frac{1}{2}\left(\frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x} + \frac{f(x_0) - f(x_0 - \Delta x)}{\Delta x}\right) = \frac{f(x_0 + \Delta x) - f(x_0 - \Delta x)}{2\Delta x}.\]
\end{defn}

\begin{rmk}
    We can approximate the second derivative $f''(x_0)$ of a function $f$ at point $x_0$ as \[f''(x_0) \approx \frac{f(x_0 + \Delta x) - 2f(x_0) + f(x_0 - \Delta x)}{\left(\Delta x\right)^2}\] by applying the forward difference formula to the backward difference formula or vice versa.
\end{rmk}

\begin{defn}
    These approximations of derivatives are known as \emph{finite differences}.
\end{defn}

\begin{exmp}
    Let $f: D \subseteq \R^2 \to \R$ be a function. We can use the central difference formula to approximate the first and second partial derivatives of $f(x, y)$ at $(x_0, y_0) \in \mathbb{D}$.

    \[\frac{\partial f}{\partial x}(x_0, y_0) \approx \frac{f(x_0 + \Delta x, y_0) - f(x_0 - \Delta x, y_0)}{2\Delta x}.\]

    \[\frac{\partial f}{\partial y}(x_0, y_0) \approx \frac{f(x_0, y_0  + \Delta y) - f(x_0, y_0 - \Delta y)}{2\Delta y}.\]

    \[\frac{\partial^2 f}{\partial x^2}(x_0, y_0) \approx \frac{f(x_0 + \Delta x, y_0) - 2f(x_0, y_0) + f(x_0 - \Delta x, y_0)}{\left(\Delta x\right)^2}.\]
\end{exmp}

\begin{rmk}
    To apply these formulas to images, we have $x_0 = j$, $y_0 = i$, and $\Delta x = \Delta j = 1$, $\Delta y = \Delta i = 1$.
\end{rmk}

\begin{exmp}
    Let $I: \mathbb{D} \to \mathbb{P}$ be an image. Then the following are approximations of the derivatives of $I$ at $(i, j) \in \mathbb{D}$:
    \[\frac{\partial^2I}{\partial y^2}(i, j) \approx \frac{I(i + 1, j) - 2I(i, j) + I(i - 1, j)}{1^2},\]
    \[\frac{\partial I}{\partial y}(i, j) \approx \frac{I(i + 1, j) - I(i - 1, j)}{2},\]
    \[\frac{\partial I}{\partial x}(i, j) \approx \frac{I(i, j + 1) - I(i, j - 1)}{2},\]
\end{exmp}

Since $\frac{\partial I}{\partial y}(i, j) \approx \frac{I(i + 1, j) - I(i - 1, j)}{2} = \frac{1}{2}I(i + 1, j) - \frac{1}{2}I(i - 1, j)$ for some image $I: \mathbb{D} \to \mathbb{P}$, we can find $\frac{\partial I}{\partial y}$ for every $(i, j) \in \mathbb{D}$ by filtering $I$ with the filter mask \[w_y = \begin{bmatrix}
    0 & -1/2 & 0 \\
    0 & 0 & 0 \\
    0 & 1/2 & 0 \\
\end{bmatrix}.\] This is equivalent to the convolution $I * h_y$, where \[h_y = \begin{bmatrix}
    0 & 1/2 & 0 \\
    0 & 0 & 0 \\
    0 & -1/2 & 0 \\
\end{bmatrix}.\]

In practice, the Prewitt or Sobel filters are much more frequently used.

Prewitt filter: \[w_y^P = \frac{1}{6}\begin{bmatrix}
    -1 & -1 & 1 \\
    0 & 0 & 0 \\
    1 & 1 & 1 \\
\end{bmatrix}\]

Sobel filter: \[w_y^S = \frac{1}{8}\begin{bmatrix}
    -1 & -2 & -1 \\
    0 & 0 & 0 \\
    1 & 2 & 1 \\
\end{bmatrix}\]

The Prewitt filter uses the average of three adjacent first derivatives in order to smooth out noise, and the Sobel filter does the same, but with a weighted average.

\end{document}
